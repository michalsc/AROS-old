#!/bin/sh
#
# Small script to check the dates of all sources and compare them to
# the ones of the HTML pages. If the sources are newer, then they
# are HTML pages are regenerated.
#

# The following env variables must be set: TOP DESTDIR DOCGENDIR CURDIR

len=`echo $TOP | wc -c`
len=`expr $len + 1`

cd="`pwd`"
cd "$TOP"
dot=0

if [ -z "$DONOTSLEEP" ]; then
    # Work around bug in inetd: When a client connects twice per second
    # to a CVS server, then inetd blocks (server might be looping) :-(
    SLEEP="sleep 2"
else
    SLEEP="true"
fi

for src in $* ; do
    dir="`echo $src | cut "-c$len-"`"
    dir="`dirname $dir`"
    name="`basename $src`"
    bname="`echo $name | cut -d. -f1`"
    html="$DESTDIR/autodocs/$bname.html"
    log="$DOCGENDIR/$bname.log"
    ehtml="$DOCGENDIR/$bname.empty"
    src="$dir/$name"

# echo "Checking $html"
# echo "Src=$src"
    regen=0
    if [ ! -e "$html" -a ! -e "$ehtml" ]; then
	regen=1
    fi
    if [ "$src" -nt "$html" -o "$CURDIR/adoc2html.gawk" -nt "$html" ]; then
	regen=1
    fi
    if [ $regen -eq 1 ]; then
	if [ $dot -ne 0 ]; then
	    echo
	    dot=0
	fi

	# TODO This doesn't work because of inetd: When CVS is
	# accessed too fequently, inetd thinks that the CVS server
	# hangs in a loop and disables it.
	if [ ! -e "$log" -o "$src" -nt "$log" ]; then
	    echo "Regenerating $log"
	    cvs log "$src" | gawk -f "$CURDIR/cvslog2html.gawk" > "$log"
	    $SLEEP
	fi
	touch "$log"
	echo "Regenerating $html"
	gawk -f "$CURDIR/adoc2html.gawk" --assign "DESTDIR=$DESTDIR" \
		"$src" "$log"
	if [ ! -e "$html" ]; then
	    touch "$ehtml"
	fi
    else
	echo -n "."
	dot=1
    fi
done

cd "$cd"
